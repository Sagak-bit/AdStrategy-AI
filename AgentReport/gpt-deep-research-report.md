# AdStrategy AI 제출물 개선 및 분석 고도화 리서치

## 프로젝트를 한 문장으로 이해시키는 핵심 서사

이 프로젝트의 “심사위원 관점에서 가장 강하게 잡아야 할 서사”는 **예측 성능 자체가 아니라, “높은 R²의 함정”을 데이터 감사로 규명하고 실제 운영 가능한 전략 설계로 전환했다**는 점입니다. 일반적으로 **target leakage(타깃 누수)** 는 예측 시점에 존재하지 않았어야 할 정보가 학습 데이터에 섞여 들어가 **검증 성능을 과대평가**하게 만들고, 운영에서는 급격히 무너질 수 있습니다. citeturn0search4turn0search8turn0search32

따라서 제출물 전체에서 메시지를 아래처럼 고정하는 것이 좋습니다.

- **훅(갈등):** “R² 0.79—너무 좋아서 오히려 의심했다.”
- **전개(추적):** “파이프라인 강화(원본 1,800 → 10,030×42, 합성 약 46%) 과정에서 Phase 3 생성 피처에 누수가 스며들 수 있음을 가정하고, ablation+검정+설명으로 ‘감사’를 수행했다.”
- **반전(발견):** “bounce_rate, load_time 등 ‘결과 이후/사후 행동’ 성격의 변수에서 누수 징후를 발견했다.”
- **결론(해결):** “누수 제거 후 R² 0.79→0.40으로 떨어졌지만, 그 수치가 바로 ‘현실에 적용 가능한 정직한 성능’이며 전략 설계의 출발점이 됐다.” citeturn0search4turn0search12

(참고로 SHAP은 개별 예측에서 피처 기여도를 **Shapley value 기반으로 정량화**하는 대표적 설명 프레임워크이므로, “누수 전후로 무엇이 모델을 지배했는가”를 보여주는 데 특히 적합합니다. citeturn0search2turn0search6turn0search10)

## 제출물별 개선 포인트

### 원페이지 기획서 문장 예시

아래는 “30초 만에 핵심 파악”을 목표로, **항목별로 바로 붙여 넣어도 되는 수준**의 문장 예시입니다(각 1~2문장).

1) **주제(What)**
- 예시 A: “AdStrategy AI는 디지털 광고 로그를 기반으로 **ROAS/CPC/CPA를 예측**하고, 예측 결과를 **예산·타깃·크리에이티브 전략으로 변환**하는 데이터 기반 설계 프레임을 제안합니다.” citeturn0search25  
- 예시 B: “핵심은 ‘모델 성능 자랑’이 아니라, **데이터 생성 파이프라인의 누수를 감사해 신뢰 가능한 전략 의사결정으로 연결**하는 것입니다.” citeturn0search4

2) **가설(Why now / So what)**
- 예시 A: “H1. Phase 3에서 생성된 일부 피처는 예측 시점에 알 수 없는 정보를 포함할 수 있으며, 이는 **비정상적으로 높은 R²**로 나타나 **의사결정을 오염**시킬 수 있다.” citeturn0search4turn0search12  
- 예시 B: “H2. 누수를 제거해도, 광고 집행 전·집행 중에 확보 가능한 변수만으로 **의미 있는 수준의 성과 예측(설명력)** 이 가능하며, 그 결과는 실행 가능한 전략 규칙(우선순위/가이드)로 전환될 수 있다.” citeturn0search4

3) **데이터 출처(Where)**
- 예시 A: “데이터는 entity["company","Kaggle","data platform"] 공개 원본 1,800건을 기반으로, 4단계 파이프라인을 통해 10,030건×42피처로 보강했습니다(합성 데이터 약 46% 포함).”
- 예시 B: “분석의 신뢰도를 위해 ‘성능 향상’보다 **데이터 생성 과정에서의 누수 가능성을 먼저 점검**하고, 누수 제거 전후의 결과를 비교 제시합니다.” citeturn0search4turn0search8  

4) **분석 방법(How)**
- 예시 A: “예측(ROAS/CPC/CPA) + 통계 검정(ANOVA·t-test·Chi²) + 설명가능성(SHAP) + ablation V1~V5를 결합해, **(1) 무엇이 유의미한가, (2) 왜 그렇게 예측하는가, (3) 어느 단계에서 성능이 ‘부풀려졌는가’** 를 체계적으로 분해했습니다.” citeturn0search2turn0search6  
- 예시 B: “특히 누수 탐지를 위해 ‘단계별 ablation’과 ‘피처 성격(사전/사후) 감사’를 병행해, 높은 R²가 실전 성능을 의미하지 않을 수 있음을 검증했습니다.” citeturn0search4turn0search12  

5) **핵심 인사이트(What we learned)**
- 예시 A: “Phase 3 데이터 생성 과정에서 bounce_rate, load_time 등 일부 피처가 **target leakage** 역할을 하며 R²를 0.79까지 끌어올렸음을 확인했습니다. 누수 제거 후 R²는 0.40으로 하락했지만, 이는 **운영 가능한 정직한 설명력**으로 재정의되었습니다.” citeturn0search4turn0search8  
- 예시 B: “따라서 본 프로젝트의 산출물은 ‘정답 맞히기 모델’이 아니라, **(1) 누수를 차단한 데이터 파이프라인, (2) 성과를 설명하는 근거(SHAP/검정), (3) 전략 의사결정으로 변환 가능한 레버 목록**입니다.” citeturn0search2turn0search6  

원페이지에서 “30초 파악”을 더 강화하는 구성 팁(문장 수준으로 반영 가능):
- 상단 3줄 고정: **문제 1줄 → 결과 1줄(0.79→0.40) → 배운 점 1줄(감사로 신뢰 확보)**  
- 오른쪽에 작은 박스: “사용 가능한 지표 정의” (ROAS/CPC/CPA는 업계 표준으로, 한 줄 정의를 붙이면 심사 편의성이 크게 올라갑니다). citeturn0search25turn0search1

### 일분 브리핑 영상 나레이션 초안

아래는 실제로 읽으면 60초 내외로 들어오는 분량을 목표로, 구간별로 끊어 쓴 초안입니다.

**(0–10초) 배경**
> “광고 데이터로 ROAS를 예측했더니 R²가 0.79가 나왔습니다. 너무 좋아서 오히려 의심했습니다. AdStrategy AI는 ‘높은 점수’가 아니라, 실무에서 믿고 쓸 수 있는 디지털 광고 전략 설계를 목표로 시작했습니다.” citeturn0search4  

**(10–25초) 분석 과정**
> “Kaggle 원본 1,800건을 4단계 파이프라인으로 10,030건×42피처로 보강했고, 약 46%는 합성 데이터였습니다. ROAS/CPC/CPA 예측 모델을 만들고, ANOVA·t-test·Chi²·SHAP, 그리고 ablation V1부터 V5까지로 ‘무엇이 성과를 설명하는지’를 단계별로 분해했습니다.” citeturn0search2turn0search6  

**(25–50초) 시각화**
> “여기 첫 그래프는 파이프라인이고, 두 번째는 누수 제거 전후 성능 비교입니다. 세 번째 SHAP 그래프에서 누수 의심 변수—bounce_rate, load_time 같은 사후 행동 지표가 상위에 뜨는 걸 확인했습니다. 해당 피처를 제거하자 R²는 0.79에서 0.40으로 떨어졌고, 그게 오히려 ‘운영 가능한 정직한 성능’이라는 결론에 도달했습니다.” citeturn0search4turn0search2  

**(50–60초) 인사이트**
> “이 프로젝트의 핵심은 예측이 아니라 감사입니다. 높은 R²의 함정을 데이터 감사로 규명했고, 이제 남은 설명력은 ‘실제로 조정 가능한 전략 레버’로 연결됩니다. AdStrategy AI는 성능 과대평가를 막는 전략 설계 기준을 제시합니다.” citeturn0search4turn0search12  

영상 제작 팁(심사 관점):
- “보여주는 그래프”는 많아도 3장으로 제한: **파이프라인 → 누수 전후 스코어 → SHAP 전후**  
- “R² 하락”을 실패처럼 말하지 말고, **정직해진 순간**으로 프레이밍(심사에서 영향력 점수가 크게 좋아집니다). citeturn0search4

### Notion 공개페이지 구성안과 섹션별 핵심 문구

entity["company","Notion","productivity software company"] 공개페이지는 “기능 나열”이 아니라 “문제 해결 과정·결과”가 보이도록, **서사형 목차**가 유리합니다(각 섹션에 들어갈 1줄 핵심 문구 포함).

1) **한 줄 요약(상단 Hero)**
- “R² 0.79의 환상을 걷어내고, 누수 제거 후 R² 0.40의 ‘현실 성능’으로 전략을 설계했다.”

2) **문제 정의**
- “광고 전략은 모델 성능이 아니라, 예측 시점에 존재하는 정보만으로 의사결정할 때 가치가 생긴다.” citeturn0search4  

3) **데이터와 파이프라인**
- “원본 1,800건을 4단계로 10,030×42까지 확장하되, 합성 데이터가 포함된 만큼 ‘정합성 검증’이 핵심이었다.” citeturn0search11  

4) **분석 설계(왜 이 조합인가)**
- “예측(ROAS/CPC/CPA)로 ‘가능성’을 만들고, 검정(ANOVA·t·Chi²)과 SHAP으로 ‘근거’를 만들고, ablation으로 ‘원인’을 분리했다.” citeturn0search2turn0search6  

5) **Leakage 감사 로그(핵심 하이라이트)**
- “Phase 3에서 사후 행동/성능 지표가 섞이며 target leakage가 발생했고, 이는 의사결정을 망가뜨리는 ‘과대평가’였다.” citeturn0search4turn0search8  

6) **누수 제거 전후 비교(결과의 재정의)**
- “R² 하락은 실패가 아니라, ‘실전에서 무너지지 않는 모델’로 바뀌었다는 증거다.” citeturn0search4  

7) **전략으로의 변환(영향력 파트)**
- “이제 모델은 캠페인 설계의 체크리스트와 우선순위(어떤 레버를 먼저 조정할지)로 번역된다.”

8) **부록(재현 가능성)**
- “데이터 생성 단계별 스냅샷, ablation V1~V5 설정, 누수 제거 기준을 공개해 재현성을 확보했다.” citeturn0search4  

## 분석 고도화 제안

기존 프레임(ANOVA, t-test, Chi², SHAP, Ablation V1~V5)을 유지하면서도 **실행력·영향력**을 끌어올리는 추가 제안들입니다. 각 제안은 “목적–방법–예상 결과–활용처”로 정리했습니다.

1) 누수 위험 점수보드

**목적:** “누수를 발견했다”를 넘어, **누수 탐지 방법론 자체를 재사용 가능한 자산**으로 만들기(실행력 가산점). citeturn0search4turn0search12  
**방법:**  
- (A) **피처 단독 예측력 스크리닝**: 각 피처 하나만으로 간단 모델을 학습해 R²(또는 상관/MI)를 산출, 비정상적으로 높은 피처를 “leak 후보”로 표기  
- (B) **피처 시간축 라벨링**: “집행 전/집행 중/집행 후(사후)”로 태깅하고, “사후 피처가 상위권이면 경고” 룰 적용  
- 도구 예: Python, scikit-learn, scipy(상관/검정), matplotlib(점수보드 시각화)  
**예상 결과:** 누수 후보(bounce_rate, load_time 등)가 “왜 문제인지”가 **표 한 장/그림 한 장**으로 즉시 납득됨. citeturn0search4turn0search8  
**활용처:** Notion(Leakage 감사 로그 섹션의 핵심 이미지), 영상(25–35초 구간 1장), 기획서(우측 요약 박스 1줄).

2) 합성 데이터 유틸리티 검증 리포트

**목적:** 합성 데이터(약 46%)가 “성능을 올리기만 한 장치”가 아니라, **분포/관계/효용이 검증된 확장**임을 보여 신뢰도와 영향력 상승. 합성 데이터는 종종 실제 데이터와 **분포 차이(shift)** 를 유발할 수 있어, 검증이 중요합니다. citeturn0search7turn0search11turn0search35  
**방법:**  
- (A) **Real vs Synthetic 분포 비교**: 피처별 KS-test(연속형), Chi²(범주형), Wasserstein distance 등으로 차이를 점수화  
- (B) **유틸리티 테스트**: (i) 원본만 학습, (ii) 합성 포함 학습, (iii) 합성만 학습으로 성능/특성 중요도(SHAP) 비교  
- (C) 관계 보존 점검: 핵심 피처 쌍의 상관/상호정보량이 원본과 유사한지 비교  
**예상 결과:** “합성 데이터가 어떤 구간에서 도움이 됐고, 어느 피처에서 분포가 흔들렸는지”가 한 장의 히트맵으로 정리됨. citeturn0search35turn0search39  
**활용처:** Notion(데이터 섹션의 신뢰도 강화), 기획서(‘데이터 신뢰성’ 한 줄), 영상(10–25초 구간에 1문장 덧붙이기).

3) 전략 의사결정 시뮬레이션

**목적:** R² 같은 모델 지표를 넘어, “이 모델이 있으면 **예산/전략이 어떻게 달라지고 어떤 이득이 생기는지**”로 영향력을 완성. (광고 KPI는 ROAS/CPC/CPA처럼 의사결정 지표로 연결될 때 가치를 발휘합니다.) citeturn0search25turn0search1  
**방법:**  
- (A) 간단한 예산 배분 규칙을 가정: “예측 ROAS 상위 캠페인에 예산 가중” vs “균등 배분”  
- (B) 과거 데이터 기준 백테스트(교차검증 fold별로): 상위 k% 선택 시 기대 ROAS/CPA 개선 추정  
- (C) 리스크 표시: 세그먼트별 성능 편차가 큰 구간은 “보수적 배분”으로 표시  
**예상 결과:** 심사위원이 가장 좋아하는 그림: “**모델이 만든 의사결정 변화 → 기대 효과**” 흐름이 1장으로 완성.  
**활용처:** 기획서(Impact 박스), Notion(전략 변환 섹션 메인), 영상(50–60초 결론을 더 강하게).

4) 세그먼트 신뢰도 맵

**목적:** “이 모델을 어디에 먼저 적용할 수 있는가?”를 답해 실행력을 강화(파일럿 범위 제안).  
**방법:**  
- (A) 채널/디바이스/노출 규모 등 세그먼트별 RMSE/MAE를 계산해 **에러 히트맵** 작성  
- (B) SHAP 전역 중요도 + 세그먼트별 중요도 비교(“세그먼트에 따라 레버가 달라지는가?”) citeturn0search2turn0search6  
**예상 결과:** “신뢰 구간이 높은(안전한) 세그먼트부터 적용”이라는 실행 계획이 자연스럽게 도출.  
**활용처:** Notion(전략 적용 로드맵), 영상(25–50초 시각화 1장).

5) 예측 불확실성(구간 예측) 추가

**목적:** 광고 운영은 변동성이 크므로, 점 예측만 제시하면 “과신”으로 보일 수 있습니다. 불확실성을 함께 제시하면 의사결정 품질이 올라갑니다(영향력/실행력 동시 강화).  
**방법:**  
- (A) Quantile regression(예: 10/50/90 분위) 또는 부트스트랩으로 예측 구간 생성  
- (B) “예산 배분은 상위 기대치가 아니라 하위(리스크) 기준으로도 판단” 같은 운영 룰 제안  
**예상 결과:** “모델이 틀릴 수 있는 범위까지 보여주는 팀”으로 신뢰도가 상승(특히 누수 이슈를 다룬 프로젝트와 잘 맞음). citeturn0search4turn0search11  
**활용처:** Notion(운영 가이드), 기획서(‘리스크 관리’ 한 줄), 영상(마지막 10초에 1문장 추가).

## 심사 관점에서의 강점과 보완점

### 강점

1) **실행력(10) 관점의 강점:**  
“성능이 좋다”에서 멈추지 않고, 데이터 생성 파이프라인의 Phase 3에서 발생한 **target leakage를 발견–제거–전후 비교로 입증**했습니다. 이는 실제 현업에서도 가장 치명적인 리스크를 먼저 제거한 접근으로, 모델이 운영에서 무너지는 전형적 원인을 정면으로 다룹니다. citeturn0search4turn0search12  

2) **상상력(10) 관점의 강점:**  
“합성 데이터로 규모를 키우고(10,030×42), 다양한 분석 도구(통계 검정+SHAP+ablation)를 연결해 ‘감사 가능한 전략 설계’라는 프레임으로 재구성”한 점은 단순 예측 과제를 넘어선 기획력입니다. SHAP을 통해 “모델이 무엇으로 성능을 만들었는지”를 설명하는 구성은 누수 전후 대비에 특히 설득력이 있습니다. citeturn0search2turn0search6  

### 보완할 점

1) **영향력(10)을 올리기 위한 보완:**  
현재 강점이 “누수 규명”에 크게 집중되어 있으므로, 심사위원 입장에서는 “그래서 실제로 예산/전략이 어떻게 바뀌나?”가 마지막 한 걸음으로 남습니다. **전략 의사결정 시뮬레이션(예산 배분/우선순위 변화)** 을 넣으면 영향력 점수가 체감 상승합니다. citeturn0search25  

2) **신뢰(credibility) 측면 보완:**  
합성 데이터 비중이 높기 때문에(약 46%), “분포/관계가 얼마나 잘 보존됐는지”를 간단히라도 제시해야 방어가 됩니다. 합성 데이터는 유용하지만 분포 차이와 관계 붕괴 위험이 있을 수 있어, 최소한의 유틸리티 검증이 프로젝트 완성도를 크게 높입니다. citeturn0search7turn0search35  

## 최종 점검 체크리스트

- 기획서 상단 3줄에 **(문제–발견–의미)** 가 들어가 있는가: “0.79→0.40 = 실패가 아니라 정직해진 전환점” citeturn0search4  
- 영상에서 ‘분석 기법 나열’이 아니라 **갈등(의심)→추적(감사)→증거(전후 그래프)→결론(전략)** 흐름이 유지되는가  
- Notion에는 최소 1개의 “결정이 바뀌는 그림”이 있는가(예: 예산 배분 시뮬레이션/세그먼트 신뢰도 맵) citeturn0search25  
- 누수 방지 기준이 재현 가능한 규칙으로 적혀 있는가(“사후 피처 태깅”, “단독 예측력 스크리닝”) citeturn0search4turn0search8
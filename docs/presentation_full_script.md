# AdStrategy AI — 발표 스크립트 (v2)

> **파일**: `AdStrategy_AI_발표자료_v2.pptx` (17장)
> **서사 구조**: 비전 → 구축 → 의심 → 발견 → 해결 → 임팩트

---

## [풀버전] 약 5분 (데모 포함)

---

### Slide 1 — 타이틀 (0:00–0:05)

**[화면]** "AdStrategy AI — 데이터 감사로 찾은 정직한 성능"

> 안녕하세요. AdStrategy AI 프로젝트를 발표하겠습니다.

---

### Slide 2 — 프로젝트 비전 (0:05–0:25) `NEW`

**[화면]** 3개 카드: $600B+ / 3개 플랫폼 / 데이터→전략

> 디지털 광고 시장은 600조 원이 넘습니다.
> Google, Meta, TikTok — 어디에, 얼마를, 언제 써야 하는지.
> 대형 에이전시가 아니면 데이터 기반으로 결정하기 어렵습니다.
>
> 그래서 질문했습니다.
> "ML 예측과 AI 에이전트로 이 의사결정을 자동화할 수 있지 않을까?"

---

### Slide 3 — 무엇을 만들었나 (0:25–0:55) `NEW`

**[화면]** 4개 카드: 데이터 파이프라인 / ML 모델 / AI 에이전트 / 웹 앱

> 만든 건 크게 네 가지입니다.
>
> 첫째, Kaggle 1,800건을 FRED, World Bank, Google Trends 같은 공공 API로 보강해서
> 10,030건 42개 피처로 키운 **데이터 파이프라인**.
>
> 둘째, ROAS, CPC, CPA를 예측하는 **XGBoost 앙상블 모델**.
>
> 셋째, GPT-4o Function Calling으로 자연어 대화만으로
> 광고 전략을 설계해주는 **AI 에이전트**.
>
> 넷째, 이 모든 걸 5개 탭으로 담은 **Streamlit 웹 앱**입니다.
>
> (잠깐 멈추고)
> 여기까지는 순조로웠습니다. **그런데...**

---

### Slide 4 — 후킹: R² = 0.79 (0:55–1:10)

**[화면]** R² = 0.79 큰 빨간 숫자

> 모델의 R²가 0.79가 나왔습니다.
>
> 마케팅 데이터에서 이건 **너무 좋은 숫자**입니다.
> Meta의 공식 MMM 도구 Robyn도 0.50에서 0.70 사이거든요.
>
> 그래서 이 모델에게 다시 물었습니다.
> "네가 거짓말하고 있는 건 아니야?"

---

### Slide 5 — 파이프라인 (1:10–1:30)

**[화면]** 4단계 파이프라인 다이어그램, Phase 3 빨간색

> 파이프라인을 다시 들여다봤습니다.
> Phase 1, 2, 4는 문제가 없었습니다.
>
> 문제는 **Phase 3** — 크리에이티브 메타데이터를 생성하는 단계에서
> **정답이 피처에 새어 들어간** 걸 발견했습니다.
> 이른바 target leakage입니다.

---

### Slide 6 — Smoking Gun (1:30–1:50)

**[화면]** 코드: `bounce_rate = 65 - ROAS × 2`

> 이것이 그 공식입니다.
>
> `bounce_rate = 65 − ROAS × 2`.
>
> ROAS가 높으면 bounce_rate가 낮아지는 **역함수**예요.
> 모델이 이걸 학습하면 사실상 정답지를 보고 시험을 치는 셈입니다.
>
> 이런 변수가 3개.
> 이 세 변수가 R² 0.79의 거의 **절반**을 만들어내고 있었습니다.

---

### Slide 7 — Waterfall R² (1:50–2:05)

**[화면]** waterfall_r2_leakage.png

> leakage 변수를 하나씩 제거하면
> R²가 **0.79 → 0.69 → 0.62 → 0.35**로 떨어집니다.
>
> 절반 이하. 하지만 이것이 정답지를 빼고 난 뒤의 **진짜 실력**입니다.

---

### Slide 8 — SHAP 대조 (2:05–2:25)

**[화면]** shap_force_leakage_vs_clean.png

> SHAP 분석이 이 차이를 더 선명하게 보여줍니다.
>
> 왼쪽, leakage 포함 모델에서는 bounce_rate가 혼자 50%를 차지합니다.
> 오른쪽, 제거 후에는 경쟁 밀도, 광고 예산, 시즌 같은
> **광고주가 통제할 수 있는 변수**들이 상위를 차지합니다.
>
> Creative 그룹의 Shapley 값은 +0.397에서 **마이너스 0.134**로 뒤집혔습니다.

---

### Slide 9 — Ablation V1→V5 (2:25–2:45)

**[화면]** ablation_guardrail.png

> 그런데 이 leakage를 어떻게 찾았을까요?
> **Ablation Study가 없었다면 절대 발견하지 못했습니다.**
>
> V1 Leave-One-Out에서 Creative 그룹의 26% 기여를 보고 의심을 시작했고,
> V2 Shapley 분해에서 86%라는 비정상 수치를 확인,
> V3에서 다른 변수를 움직여도 Creative가 지배하는 걸 검증,
> V4에서 bounce_rate 단독 41%를 특정하고,
> V5에서 데이터 생성 코드를 직접 감사해서 공식을 찾아냈습니다.
>
> R²가 0.79라고 좋아하고 넘어갔으면 영원히 몰랐을 겁니다.
> **체계적으로 의심하는 방법론**이 있었기에 가능한 발견이었습니다.

---

### Slide 10 — LIVE DEMO (2:45–3:35)

**[화면]** "LIVE DEMO" → Streamlit 앱 전환

> 자, 이 분석이 실제로 어떻게 쓰이는지 보여드리겠습니다.

**[→ Streamlit 앱 전환]**

> 이것이 AdStrategy AI의 웹 인터페이스입니다.
> 대시보드, AI 에이전트, Leakage 감사, 예산 시뮬레이터, 내 데이터 분석.
> 5개 탭으로 되어 있습니다.

**[AI 에이전트 탭 → Quick Start 클릭]**

> "핀테크 앱 광고를 미국에서 시작하려고 해요."
> AI 에이전트가 추가 정보를 물어보고, 답변하면...

**[에이전트 응답 + 차트 생성]**

> 이렇게 플랫폼별 ROAS 예측과 전략 추천이 나옵니다.
> 모든 결과 하단에 "honest R² 0.35 모델 기반"이라는 투명성 고지가 있습니다.

**[예산 시뮬레이터 탭 전환 → 슬라이더]**

> 예산 시뮬레이터에서는 플랫폼별 반응 곡선을 직접 조작할 수 있습니다.

**[→ 슬라이드 복귀]**

---

### Slide 11 — 예산 재할당 (3:35–3:55)

**[화면]** budget_reallocation_impact.png

> 정직한 모델로도 전략적 가치를 뽑아낼 수 있습니다.
>
> 예측 ROAS 상위 20% 캠페인에 예산의 70%를 집중하면
> **가중 ROAS가 170% 개선**됩니다.
>
> R²가 0.35여도 방향은 맞습니다.
> 어떤 캠페인이 더 나은지를 가리키는 데는 충분합니다.

---

### Slide 12 — 3가지 산출물 (3:55–4:15)

**[화면]** 3개 카드

> 정리하면, 핵심 산출물은 세 가지입니다.
>
> 첫째, 합성 데이터 프로젝트에서 재사용 가능한 **5단계 leakage 탐지 템플릿**.
> 둘째, 예산 재할당과 플랫폼 반응 곡선을 제공하는 **전략 의사결정 도구**.
> 셋째, 자연어 대화로 전략을 설계하는 **GPT-4o AI 에이전트**.

---

### Slide 13 — 데이터 투명성 (4:15–4:30)

**[화면]** 한계 테이블

> 한계도 투명하게 말씀드립니다.
> 합성 데이터 46% 포함, honest R² 0.35.
> 하지만 합성 데이터가 주요 순위에 영향을 주지 않음을 검증했고,
> 이 프로젝트의 가치는 예측 정확도가 아니라
> **높은 R²의 함정을 발견하고 교정한 과정** 자체입니다.

---

### Slide 14 — 핵심 메시지 (4:30–4:50)

**[화면]** "높은 R²는 좋은 모델의 증거가 아니라 감사의 출발점이다"

> R² 0.79에서 0.35로의 하락은 실패가 아닙니다.
> **정직해진 전환점**이었습니다.
>
> 이 프로젝트의 산출물은 예측 모델이 아니라,
> **누수를 잡아내는 데이터 감사 프레임워크** 그 자체입니다.
>
> (한 박자 쉬고)
> **AI는 도구입니다.**
> 파이프라인도 만들어주고, 코드도 작성해주고, 분석도 해줍니다.
> 하지만 그 도구가 **틀렸을 때 그것을 잡아내는 건, 사람의 역할**입니다.

---

### Slide 15 — 감사합니다 (4:45–4:50)

**[화면]** URL + 감사합니다

> 감사합니다. Live Demo와 코드는 화면의 URL에서 확인하실 수 있습니다.

---

## 풀버전 타이밍

| # | 슬라이드 | 구간 | 초 | 핵심 |
|---|---------|------|-----|------|
| 1 | 타이틀 | 0:00–0:05 | 5 | 인사 |
| 2 | **비전** | 0:05–0:25 | 20 | 왜 이 프로젝트를? |
| 3 | **구축** | 0:25–0:55 | 30 | 뭘 만들었나 |
| 4 | 후킹 | 0:55–1:10 | 15 | R²=0.79 의심 |
| 5 | 파이프라인 | 1:10–1:30 | 20 | Phase 3 문제 |
| 6 | Smoking Gun | 1:30–1:50 | 20 | 공식 발견 |
| 7 | Waterfall | 1:50–2:05 | 15 | R² 하락 |
| 8 | SHAP | 2:05–2:25 | 20 | 기여도 역전 |
| 9 | Ablation | 2:25–2:45 | 20 | 5단계 감사 |
| 10 | LIVE DEMO | 2:45–3:35 | 50 | Streamlit |
| 11 | Budget | 3:35–3:55 | 20 | ROAS +170% |
| 12 | 산출물 | 3:55–4:15 | 20 | 3가지 |
| 13 | 투명성 | 4:15–4:30 | 15 | 한계 |
| 14 | 핵심 메시지 | 4:30–4:45 | 15 | 결론 |
| 15 | 감사합니다 | 4:45–4:50 | 5 | 마무리 |

**총: ~4분 50초**

---
---

## [1분 전용] `AdStrategy_AI_1min_DA.pptx` — 7장 + 데모 영상

> **파일**: `AdStrategy_AI_1min_DA.pptx` (7장 슬라이드, DA = Data Analysis 중심)
> **서사**: 가설 → 파이프라인 → 분석 → 검증 → 활용 → 임팩트
> **핵심**: 데이터 분석 프로세스 자체가 주인공. 슬라이드 7장, 데모 영상 편집 삽입.

---

### Slide 1 — 가설 (0:00–0:07) 7초

**[화면]** "AdStrategy AI" + 가설 카드: "광고 예산 배분을 데이터로 최적화할 수 있는가?" + DATA/MODEL/AGENT 키워드

> 광고 예산 배분을 데이터로 최적화할 수 있는가.
> 공개 데이터 만 건을 보강하고, 모델과 에이전트까지 연결한 프로젝트입니다.

---

### Slide 2 — 파이프라인 (0:07–0:15) 8초

**[화면]** 6단계 가로 플로우: 데이터 수집 → 4단계 보강 → ML 모델링 → Ablation 감사(빨간 강조) → AI 에이전트 → 광고주 활용

> 공개 데이터를 4단계로 만 건까지 보강하고,
> 모델, 감사, 에이전트까지 하나의 파이프라인으로 연결했습니다.
> 그런데 —

---

### Slide 3 — Ablation → Leakage 발견 (0:15–0:25) 10초

**[화면]** 좌: R²=0.79 / 우: 코드 에디터 `bounce_rate = 65 - ROAS * 2`

> 예측 모델의 R²가 0.79로 비정상적으로 높았습니다.
> Ablation Study로 원인을 추적했더니,
> 정답을 암시하는 데이터 누수 변수가 학습에 섞여 있었습니다.

*(코드 수식은 화면으로만 보여주고, 입으로 읽지 않습니다)*

---

### Slide 4 — 교정 결과 (0:25–0:33) 8초

**[화면]** waterfall_r2_leakage.png

> 해당 변수들을 모두 제거하자 R²는 0.35로 떨어졌습니다.
> 비로소 정답지를 빼고 푼, 모델의 **'진짜 실력'**을 확인한 겁니다.

---

### Slide 5 — 분석→에이전트 연결 + 데모 (0:33–0:47) 14초

**[화면]** 상단: 미니 파이프라인 (Honest Model → GPT-4o → 4 Tools → Streamlit → 광고주) / 하단: LIVE DEMO + URL → 데모 영상 전환

> 이 분석 결과를 AI 에이전트와 연결해,
> 광고주가 대화만으로 데이터 기반 전략을 받을 수 있게 했습니다.

*(슬라이드 2초 노출 후 Streamlit 녹화 영상으로 전환)*

---

### Slide 6 — +170% 임팩트 (0:47–0:53) 6초

**[화면]** "+170%" 큰 초록 숫자 + 설명 카드 2개

> 이 정직해진 모델로 상위 캠페인에 예산을 집중 시뮬레이션한 결과,
> ROAS를 170%까지 개선할 수 있었습니다.

---

### Slide 7 — 핵심 메시지+감사 (0:53–1:00) 7초

**[화면]** 인용문 + "감사합니다" + GitHub 로고 + URL

> AI의 오류를 잡아내는 건 결국 사람의 몫입니다.
> 정직한 데이터가 진짜 가치를 만듭니다.
> 감사합니다.

---

### 1분 타이밍 총정리

| # | 슬라이드 | 시간 | 초 | 핵심 |
|---|---------|------|-----|------|
| 1 | 가설 | 0:00–0:07 | 7 | 무엇을 검증하려 했나 |
| 2 | 파이프라인 | 0:07–0:15 | 8 | E2E 플로우 + "그런데 —" |
| 3 | Ablation→Leakage | 0:15–0:25 | 10 | R²=0.79 + 누수 발견 |
| 4 | Waterfall | 0:25–0:33 | 8 | 교정 후 진짜 실력 |
| 5 | **분석→에이전트+데모** | 0:33–0:47 | 14 | 파이프라인 연결 + Streamlit |
| 6 | +170% | 0:47–0:53 | 6 | 비즈니스 임팩트 |
| 7 | 결론+감사 | 0:53–1:00 | 7 | AI는 도구 + 정직한 데이터 |

**총: 60초** (~300자, 데이터 분석 프로세스 중심)

---

### 데모 영상 편집 가이드

Streamlit 데모를 **미리 녹화**한 뒤 속도 편집으로 14초에 압축합니다.

| 구간 | 원본 | 속도 | 편집 후 | 비고 |
|------|------|------|---------|------|
| ① Quick Start 버튼 클릭 | ~2초 | 원속 | 2초 | 자연스럽게 |
| ② 타이핑 (질문 입력) | ~12초 | **10x** | 1.2초 | 빨리감기 느낌 |
| ③ 모델 응답 대기 (스피너) | ~8초 | **컷** | 0초 | 완전 삭제 |
| ④ 응답 텍스트 생성 | ~12초 | **3x** | 4초 | 텍스트 올라오는 게 보임 |
| ⑤ 차트 생성 확인 | ~3초 | 원속 | 3초 | 핵심 장면, 천천히 |
| ⑥ 탭 전환 + 슬라이더 조작 | ~8초 | **5x** | 1.6초 | 빨리감기 |
| ⑦ 반응 곡선 결과 정지 | ~3초 | 원속 | 3초 | 마지막 정지 화면 |

**편집 후 총: ~14.8초 → 14초 맞춤**

> **녹화 팁**:
> - OBS로 전체 화면 녹화 (1080p)
> - Streamlit 앱을 미리 열어두고 API 키 세팅 완료 상태에서 시작
> - 시나리오: Quick Start → "핀테크 앱 광고를 미국에서 시작하려고 해요"
> - 편집: CapCut / DaVinci Resolve (무료) / Premiere Pro 어디든 OK
> - 나레이션은 슬라이드 나레이션과 이어서 녹음하거나, 데모 위에 자막만 올려도 충분

---

## Q&A 예상 질문 (Appendix 슬라이드 활용)

### Q1. "R² 0.35면 쓸 수 있는 건가요?"

> 마케팅 데이터에서 R² 0.20~0.50은 실무 타당 범위입니다 (Leeflang et al., 2009).
> Meta Robyn도 R² 0.50~0.70이고, 개별 수치 정밀도보다
> 플랫폼·캠페인 간 상대 비교 가이드가 목적입니다.
> 상위 20% 집중 시 ROAS +170%가 그 증거입니다.

### Q2. "합성 데이터 46%의 영향은?"

> 플랫폼·산업 순위가 원본과 동일하게 유지됩니다.
> K-S test로 분포 유사성을 확인했고, 정확 일치 행 0%로 프라이버시도 보존됩니다.
> 다만 개별 피처 수준의 인과 관계는 합성 데이터로 추론 불가하며,
> 이를 문서에 명시했습니다.

### Q3. "이 프레임워크를 다른 곳에도 쓸 수 있나요?"

> 네. 5단계 감사(Leave-One-Out → Shapley → Robustness → 개별 분해 → Data Audit)는
> 합성 데이터를 사용하는 어떤 ML 프로젝트에서든 재사용 가능합니다.
> 특히 R²가 비정상적으로 높을 때 의심의 출발점으로 쓸 수 있습니다.

### Q4. "AI 도구를 얼마나 활용했나요?"

> 파이프라인, 코드, UI, 문서화 전 과정에서 활용했습니다.
> 하지만 leakage를 의심하고, 5단계 감사를 설계하고,
> R² 하락을 "교정"으로 해석한 건 사람의 판단입니다.
> AI는 도구이고, 도구가 틀렸을 때 잡아내는 건 사람의 역할입니다.
